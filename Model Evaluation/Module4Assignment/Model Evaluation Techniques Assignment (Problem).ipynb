{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"R0_JVd0BwbfP"},"source":["<center><img src=\"https://gitlab.com/accredian/insaid-data/-/raw/main/Logo-Accredian/Case-Study-Cropped.png\" width= 30% /></center>\n","\n","# <center><b>Model Evaluation Techniques Assignment (Problem)<b></center>"]},{"cell_type":"markdown","metadata":{"id":"YdVgr1-aZihs"},"source":["---\n","# **Table of Contents**\n","---\n","\n","**1.** [**Introduction**](#Section1)<br>\n","**2.** [**Problem Statement**](#Section2)<br>\n","**3.** [**Installing & Importing Libraries**](#Section3)<br>\n","  - **3.1** [**Installing Libraries**](#Section31)\n","  - **3.2** [**Upgrading Libraries**](#Section32)\n","  - **3.3** [**Importing Libraries**](#Section33)\n","\n","**4.** [**Data Acquisition & Description**](#Section4)<br>\n","  - **4.1** [**Data Description**](#Section41)\n","  - **4.2** [**Data Information**](#Section42)\n","\n","**5.** [**Data Pre-processing**](#Section5)<br>\n","  - **5.1** [**Pre-Profiling Report**](#Section51)<br>\n","\n","**6.** [**Exploratory Data Analysis**](#Section6)<br>\n","**7.** [**Data Post-Processing**](#Section7)<br>\n","**8.** [**Model Development & Evaluation**](#Section8)<br>\n","**9.** [**Conclusion**](#Section9)<br>"]},{"cell_type":"markdown","metadata":{"id":"LvwK1yHrZ0f5"},"source":["---\n","<a name = Section1></a>\n","# **1. Introduction**\n","---\n","\n","- **Evaluating** a machine learning model is as **important** as **building** it.\n","\n","- We are creating models to perform on **new, previously unseen data**.\n","\n","- Hence, a **thorough** and **versatile evaluation** is required to create a **robust** model.\n","\n","- When it comes to **classification models**, evaluation process gets somewhat tricky.\n","\n","- The various evaluation metrics that will be used are:\n","\n","  - **Accuracy:** It is a metric that calculates the number of correct predictions divided by the total number of predictions.\n","\n","  - **Precision:** It measures how good our model is when the prediction is positive.\n","\n","  - **Recall:** It measures how good our model is at correctly predicting positive classes.\n","\n","  - **F1-Score:** It is the weighted average of precision and recall.\n","\n","  - **ROC Curve:** It summarizes the performance of the model at different threshold values.\n","\n","  - **Precision Recall Curve:** It shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z-SF3dcRaV14"},"source":["---\n","<a name = Section2></a>\n","# **2. Problem Statement**\n","---\n","\n","- A condition in which the tissues in the **kidney** become **inflamed** and have problems filtering waste from the blood.\n","\n","- Nephritis may be caused by **infection**, **inflammatory** conditions, certain **genetic conditions**, and other diseases or conditions.\n","\n","- XYB Diagnostics are **renowned** for their **expertise** in diagnosing nephritis.\n","\n","<center><img src=\"https://us.123rf.com/450wm/alkov/alkov1808/alkov180800012/112010269-illustration-of-the-accute-pyelonephritis-with-the-pus-inside-the-kidney-and-severe-inflammation-nor.jpg?ver=6\" width=30%></center>\n","\n","- They want to go a step ahead and **automate** the process of **detecting nephritis** depending on various criteria.\n","\n","- For this automation, they have hired a data scientist. Let's say it is you.\n","\n","- You are provided with a **historical data of patients** who were suffered from nephritis and some patients who showed similar symptoms to nephritis.\n","\n","- Your task is to **create a model** based on this data so that it can be used in real time to **determine** if a patient is **suffering from nephritis**."]},{"cell_type":"markdown","metadata":{"id":"k5T9XBDAaikg"},"source":["---\n","<a name = Section3></a>\n","# **3. Installing & Importing Libraries**\n","---"]},{"cell_type":"markdown","metadata":{"id":"drocKDJ2amBg"},"source":["<a name = Section31></a>\n","### **3.1 Installing Libraries**"]},{"cell_type":"code","metadata":{"id":"OnkW7DSeZRWB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687416653866,"user_tz":-330,"elapsed":30144,"user":{"displayName":"Sagar Sinha","userId":"07967757319436915271"}},"outputId":"bc274e67-c7fb-41a4-8667-23ae36e788be"},"source":["!pip install -q datascience                                         # Package that is required by pandas profiling\n","!pip install -q pandas-profiling                                    # Library to generate basic statistics about data\n","!pip install -q yellowbrick                                         # Toolbox for Measuring Machine Performance"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.4/455.4 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","metadata":{"id":"3QmMddCSaozh"},"source":["<a name = Section32></a>\n","### **3.2 Upgrading Libraries**\n","\n","- **After upgrading** the libraries, you need to **restart the runtime** to make the libraries in sync.\n","\n","- Make sure not to execute the cell above (3.1) and below (3.2) again after restarting the runtime."]},{"cell_type":"code","metadata":{"id":"EEv5mic6aop0"},"source":["!pip install -q --upgrade pandas-profiling\n","!pip install -q --upgrade yellowbrick"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Kfl3PunatnY"},"source":["<a name = Section33></a>\n","### **3.3 Importing Libraries**"]},{"cell_type":"code","metadata":{"id":"bl9dW2NRaom8"},"source":["#-------------------------------------------------------------------------------------------------------------------------------\n","import pandas as pd                                                 # Importing for panel data analysis\n","from pandas_profiling import ProfileReport                          # Import Pandas Profiling (To generate Univariate Analysis)\n","pd.set_option('display.max_columns', None)                          # Unfolding hidden features if the cardinality is high\n","pd.set_option('display.max_colwidth', None)                         # Unfolding the max feature width for better clearity\n","pd.set_option('display.max_rows', None)                             # Unfolding hidden data points if the cardinality is high\n","pd.set_option('mode.chained_assignment', None)                      # Removing restriction over chained assignments operations\n","pd.set_option('display.float_format', lambda x: '%.2f' % x)         # To suppress scientific notation over exponential values\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import numpy as np                                                  # Importing package numpys (For Numerical Python)\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import matplotlib.pyplot as plt                                     # Importing pyplot interface using matplotlib\n","import seaborn as sns                                               # Importin seaborm library for interactive visualization\n","%matplotlib inline\n","#-------------------------------------------------------------------------------------------------------------------------------\n","from sklearn.model_selection import train_test_split                # To split the data into train and test datasets\n","from sklearn.linear_model import LogisticRegression                 # To instantiate a Logistic Regression Model\n","from sklearn.metrics import accuracy_score                          # To calculate the accuracy of a classifier\n","from sklearn.metrics import precision_score                         # To calculate the precision of a classifier\n","from sklearn.metrics import recall_score                            # To calculate the recall of a classifier\n","from sklearn.metrics import f1_score                                # To calculate the f1-score of a classifier\n","from sklearn.metrics import precision_recall_curve                  # To plot the precision-recall curve of a classifier\n","#-------------------------------------------------------------------------------------------------------------------------------\n","import warnings                                                     # Importing warning to disable runtime warnings\n","warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17HjjOUVa2BR"},"source":["---\n","<a name = Section4></a>\n","# **4. Data Acquisition & Description**\n","---\n","\n","- The data was created by a **medical expert** as a data set to **help build a system** which will perform the presumptive **diagnosis of nephritis**.\n","\n","</br>\n","\n","| Records | Features | Dataset Size |\n","| :-- | :-- | :-- |\n","| 120 | 8 | 4 KB|\n","\n","</br>\n","\n","| Id | Features | Description |\n","| :-- | :-- | :-- |\n","| 01 | **temperature** | Temperature of patient |\n","| 02 | **nausea** | Occurrence of nausea |\n","| 03 | **lumbar_pain** | Muscle strain is often the cause of back pain from heavy lifting or vigorous exercise |\n","| 04 | **urine_pushing** | Urine pushing (continuous need for urination) |\n","| 05 | **micturition_pain** | Pain while urinating |\n","| 06 | **burning** | Burning of urethra, itch, swelling of urethra outlet |\n","| 07 | **inflamation** | Inflammation of urinary bladder |\n","| 08 | **nephritis** | Nephritis of renal pelvis origin |"]},{"cell_type":"code","metadata":{"id":"cCg5kJuvaokI"},"source":["data = pd.read_csv(filepath_or_buffer='https://raw.githubusercontent.com/insaid2018/Term-2/master/Data/diagnosis.csv', delimiter='\\t')\n","print('Data Shape:', data.shape)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTHzKhlGbZN5"},"source":["<a name = Section41></a>\n","### **4.1 Data Description**\n","\n","- In this section we will get **information about the data** and see some observations."]},{"cell_type":"code","metadata":{"id":"5WOdH51iaobL"},"source":["data.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S5mvRKbpbjSq"},"source":["<a name = Section42></a>\n","### **4.2 Data Information**\n","\n","- In this section we will see the **information about the types of features**."]},{"cell_type":"code","metadata":{"id":"qqCFCElYbaZ7"},"source":["data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RIhLwaKObmSw"},"source":["<a name = Section5></a>\n","\n","---\n","# **5. Data Pre-Processing**\n","---"]},{"cell_type":"markdown","metadata":{"id":"qqPyw_4ubnuh"},"source":["<a name = Section51></a>\n","### **5.1 Pre Profiling Report**\n","\n","- For **quick analysis** pandas profiling is very handy.\n","\n","- Generates profile reports from a pandas DataFrame.\n","\n","- For each column **statistics** are presented in an interactive HTML report."]},{"cell_type":"code","metadata":{"id":"ZxzDuAo5baXU"},"source":["profile = ProfileReport(df=data)\n","profile.to_file(output_file='Pre Profiling Report.html')\n","print('Accomplished!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9LDQHMs4bw-H"},"source":["**Performing Operations**"]},{"cell_type":"markdown","metadata":{"id":"MsOfbgWbJoOR"},"source":["\n","---\n","**<h4>Question 1:** Create a function that performs the following cleaning operations on the dataset:</h4>\n","\n","---\n","\n","- Removes the whitespaces from column names.\n","\n","- Removes the duplicate rows from the dataset.\n","\n","- Maps 1 for 'yes' and 0 for 'no' for all categorical variables.\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- You can use `.str.replace(' ', '')` to remove whitespaces from the column names.\n","\n","- You can use `.drop_duplicates` method to remove the duplicates.\n","\n","- You can use `.map` method for the required changes.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"CgdW9cXkJAJh"},"source":["def clean_data(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSYA-9V1J5m-"},"source":["clean_data(data=data)\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8pjjM512K6-X"},"source":["<a name = Section52></a>\n","### **5.2 Post Profiling Report**\n","\n","- Since we only mapped some of the features and removed duplicate rows from the dataset, we won't apply profiling to the dataset again."]},{"cell_type":"markdown","metadata":{"id":"ncoTDlnRb41I"},"source":["<a name = Section6></a>\n","\n","---\n","# **6. Exploratory Data Analysis**\n","---"]},{"cell_type":"markdown","metadata":{"id":"hYNV2qhQKiRT"},"source":["\n","---\n","**<h4>Question 2:** Create a function that checks patients experienced burning sensation and were diagnosed with nephritis.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create a 15x7 inch figure\n","\n","- You can use `sns.counplot` method on burning feature and keep nephritis as hue.\n","\n","- Add cosmetics like grid and title\n","\n","- Keep the tick size as 12, label size as 14 and title size as 16.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"OhqKfF_uK0ie"},"source":["def burning(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJLZmnAgK02Y"},"source":["burning(data=data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zzJGUQHretA4"},"source":["\n","---\n","**<h4>Question 3:** Create a function that checks relation between nausea and body temperature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create a 15x7 inch figure\n","\n","- You can use `sns.histplot` method on temperature feature keeping nausea as hue.\n","\n","- Add cosmetics like grid and title\n","\n","- Keep the tick size as 12, label size as 14 and title size as 16.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"QdqU4-7AfDTp"},"source":["def nausea_n_temp(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IizBgPKxfj-e"},"source":["nausea_n_temp(data=data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cFUqzIhag47i"},"source":["\n","---\n","**<h4>Question 4:** Create a function that checks relation between nephritis and body temperature.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create a 15x7 inch figure\n","\n","- You can use `sns.kdeplot` method on temperature feature keeping nephritis as hue.\n","\n","- Add cosmetics like grid and title\n","\n","- Keep the tick size as 12, label size as 14 and title size as 16.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"jz3DgDZZkxMK"},"source":["def niphritis_n_temp(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsAsFXjBk6B5"},"source":["niphritis_n_temp(data=data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SDKDzuI_nOYh"},"source":["\n","---\n","**<h4>Question 5:** Create a function that checks relation between nephritis, nausea and inflammation.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","\n","\n","- Create a 15x7 inch figure\n","\n","- You can use `sns.countplot` method on `inflammation` feature keeping hue as `nephritis` and keep `data=data[data['nausea']==0]` or `data=data[data['nausea']==1]`.\n","\n","- Add cosmetics like grid and title\n","\n","- Keep the tick size as 12, label size as 14 and title size as 16.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"nwtwJUS3nj0R"},"source":["def nausea_n_nephritis(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5857Khp3n4yb"},"source":["nausea_n_nephritis(data=data[data['nausea']==0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAcB7RiTcrYf"},"source":["<a name = Section7></a>\n","\n","---\n","# **7. Data Post-Processing**\n","---"]},{"cell_type":"markdown","metadata":{"id":"IQrdHcqBgvHJ"},"source":["<a name = Section71></a>\n","### **7.1 Feature Extraction**\n","\n","- In this section, we will extract the important features and seperate the independent and dependent variables."]},{"cell_type":"markdown","metadata":{"id":"H3ThcctJnrMH"},"source":["---\n","**<h4>Question 6:** Create a function that creates two dataframes for dependent and independent features.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Create input dataframe X by dropping only \"nephritis\" feature from axis 1.\n","\n","- Create target series by using \"nephritis\" as value.\n","\n","</details>\n"]},{"cell_type":"code","metadata":{"id":"NmV_PvKMobxn"},"source":["def seperate_Xy(data=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vHdxyGC2gqvC"},"source":["X, y = seperate_Xy(data=data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aHC_XfX7g_WZ"},"source":["<a name = Section72></a>\n","### **7.2 Data Preparation**\n","\n","- Now we will **split** our **data** in **training** and **testing** part for further development."]},{"cell_type":"markdown","metadata":{"id":"YAysVX6qqHKD"},"source":["---\n","**<h4>Question 7:** Create a function that splits the data into train and test datasets while keeping random state as 42.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Use `train_test_split()` to split the dataset.\n","\n","- Use `test_size` of **0.30**\n","\n","- Use `random_state` equal to **42**.\n","\n","- **Stratify** the target variable.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"ATpzPPfsgqrO"},"source":["def Xy_splitter(X=None, y=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GV5DEP2p__4"},"source":["X_train, X_test, y_train, y_test = Xy_splitter(X=X, y=y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"coaGUA33hDGK"},"source":["<a name = Section8></a>\n","\n","---\n","# **8. Model Development & Evaluation**\n","---\n","\n","- In this section we will develop a Logistic Regression model, check it's performance using different metrics."]},{"cell_type":"markdown","metadata":{"id":"TesmlgEubunV"},"source":["<a name = Section81></a>\n","### **8.1 Model Development & Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"Wesgk1UBguEB"},"source":["---\n","**<h4>Question 8:** Create a function that instantiates a logistic regression model, fits the model on train set, makes predictions on test set and returns those predictions.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Instantiate a logistic regression model using LogisticRegression().\n","\n","- Use `class_weight = 'balanced'`.\n","\n","- `Fit` the model on training set.\n","\n","- `Predict` the values on the train set and the test set.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"RQbPcrKVsCNd"},"source":["def train_n_eval():\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lYZi1rAsxNd"},"source":["y_pred_train, y_pred, y_test_pred_proba, y_train_pred_proba = train_n_eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cT3oFW4dOoK8"},"source":["\n","---\n","**<h4>Question 9:** Create a function that evaluates the model's training and testing predictions on the given metrics:</h4>\n","\n","---\n","\n","- Accuracy score\n","- Precision score\n","- Recall score\n","- F1 score\n","\n","\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- Evaluate the predictions using the `accuracy_score`, `precision_score`, `recall_score` and `f1_score` on the train set and the test set.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"sVoXwiNgOujd"},"source":["def calculate_metrics(y_pred=None, y_pred_train=None):\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgX1BFgpUyjH"},"source":["calculate_metrics(y_pred=y_pred, y_pred_train=y_pred_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jgUtrseRU-Vr"},"source":["\n","---\n","**<h4>Question 10:** Create a function that plots the Precision-Recall curve for the predictions on train and test data.</h4>\n","\n","---\n","\n","<details>\n","\n","**<summary>Hint:</summary>**\n","\n","- For plot_precision_recall_builder():\n","\n","  - Calculate the precision and recall values at various thresholds using `precision_recall_curve()` method.\n","\n","  - Calculate the average precision and recall values using `np.mean()`\n","\n","  - Plot the curve using  `sns.lineplot()` and plot the average precision and recall values with respect to `[0, 1]`.\n","\n","  - Add some cosmetics like title, grid and legend.\n","\n","  - Keep label size as 14 and title size as 16.\n","\n","- For plot_precision_recall():\n","\n","  - Create 2 subplots and call the builder function seperately for train predictions and test predictions.\n","\n","  - Add some more cosmetics like super title.\n","\n","</details>"]},{"cell_type":"code","metadata":{"id":"W3VtR9BaF66h"},"source":["def plot_precision_recall_builder(y_true, y_pred, train_or_test):\n","  '''\n","  y_true: Acutal values of the target\n","  y_pred: Predicted values of the target. Either predict_proba or decision_function\n","  line_show: Plot average values \"precision\" or \"recall\"\n","  train_or_test: Train Data or Test Data\n","  '''\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p2PqcGpWbhCQ"},"source":["def plot_precision_recall():\n","  # Write your code here..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AC_tzi_bu_s"},"source":["plot_precision_recall()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9hPQ3ufehNnp"},"source":["<a name = Section9></a>\n","\n","---\n","# **9. Conclusion**\n","---\n","\n","- We have seen that **inflammation** is **not relevant** to **nephritis** according to our data.\n","\n","- Body **temperature** and **nausea** play an **important role** in determining if a patient suffers from **nephritis**.\n","\n","- We have also **developed** a model and successfully **tested** it on various evaluation metrics.\n","\n","- Although based on **patient's temperature** and **responses**, we can **predict** if the patient suffers from nephritis or not.\n","\n","- If we can get a **better snapshot of data** and more features that relate to nephritis, we can train a model ready for **real-world information**."]}]}