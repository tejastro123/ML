{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0063331c",
   "metadata": {},
   "source": [
    "<img src=\"https://devra.ai/analyst/notebook/2271/image.jpg\" style=\"width: 100%; height: auto;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fc07f",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; border-radius:15px; padding:15px; color:white; margin:0; font-family: 'Orbitron', sans-serif; background: #2E0249; background: #11001C; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.3); overflow:hidden; margin-bottom: 1em;\"><div style=\"font-size:150%; color:#FEE100\"><b>Air Quality and Health Outcomes Analysis</b></div><div>This notebook was created with the help of <a href=\"https://devra.ai/ref/kaggle\" style=\"color:#6666FF\">Devra AI</a></div></div>Air quality and respiratory health outcomes data present plenty of challenges and opportunities to uncover hidden correlations. We dive into the intricacies of pollutant levels, weather factors, and hospital admissions to reveal stories that challenge our assumptions about urban living. If you find this notebook useful, please consider upvoting it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6362fb7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Data Loading and Preprocessing](#Data-Loading-and-Preprocessing)\n",
    "- [Data Cleaning and Preprocessing](#Data-Cleaning-and-Preprocessing)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Predictive Modeling](#Predictive-Modeling)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2d4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # set Agg backend for matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# For model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Additional inline configuration\n",
    "plt.switch_backend('Agg')  # if only plt is used, ensure using Agg backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d682df",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "We start by loading the dataset from the provided CSV. Note that the file encoding is ISO-8859-1 and the delimiter is a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c971d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>date</th>\n",
       "      <th>aqi</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>hospital_admissions</th>\n",
       "      <th>population_density</th>\n",
       "      <th>hospital_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>65</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>38.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>Rural</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beijing</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>137</td>\n",
       "      <td>33.7</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>266</td>\n",
       "      <td>43.0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>57.3</td>\n",
       "      <td>36.4</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>293</td>\n",
       "      <td>33.7</td>\n",
       "      <td>37.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>42.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>Urban</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>493</td>\n",
       "      <td>50.3</td>\n",
       "      <td>34.8</td>\n",
       "      <td>31.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>33.5</td>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city        date  aqi  pm2_5  pm10   no2    o3  temperature  \\\n",
       "0  Los Angeles  2020-01-01   65   34.0  52.7   2.2  38.5         33.5   \n",
       "1      Beijing  2020-01-02  137   33.7  31.5  36.7  27.5         -1.6   \n",
       "2       London  2020-01-03  266   43.0  59.6  30.4  57.3         36.4   \n",
       "3  Mexico City  2020-01-04  293   33.7  37.9  12.3  42.7         -1.0   \n",
       "4        Delhi  2020-01-05  493   50.3  34.8  31.2  35.6         33.5   \n",
       "\n",
       "   humidity  hospital_admissions population_density  hospital_capacity  \n",
       "0        33                    5              Rural               1337  \n",
       "1        32                    4              Urban               1545  \n",
       "2        25                   10           Suburban               1539  \n",
       "3        67                   10              Urban                552  \n",
       "4        72                    9           Suburban               1631  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = 'D:/DSMLAI(insaid)/ML/DATA SETS/air_quality_health_dataset.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1', delimiter=',')\n",
    "    print('Data loaded successfully.')\n",
    "except Exception as e:\n",
    "    print('Error loading data:', e)\n",
    "\n",
    "# Display the first few rows as a sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f0c24",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "In this section we address common data quality issues. Note the following steps:\n",
    "\n",
    "- For the `date` column, we convert the string representation to a datetime type. This is critical for time-series analyses later.\n",
    "- We check for missing values and decide on appropriate imputations or dropping strategies.\n",
    "- For columns with unexpected data types (for instance, `population_density` which is encoded as a string), further conversion logic might be necessary.\n",
    "\n",
    "The dry truth is: good data cleaning is 80% of the work. Let us get this done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580f1f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "city                   0\n",
      "date                   0\n",
      "aqi                    0\n",
      "pm2_5                  0\n",
      "pm10                   0\n",
      "no2                    0\n",
      "o3                     0\n",
      "temperature            0\n",
      "humidity               0\n",
      "hospital_admissions    0\n",
      "population_density     0\n",
      "hospital_capacity      0\n",
      "dtype: int64\n",
      "Converted population_density to numeric where possible.\n",
      "Data types after processing:\n",
      "city                                  object\n",
      "date                          datetime64[ns]\n",
      "aqi                                    int64\n",
      "pm2_5                                float64\n",
      "pm10                                 float64\n",
      "no2                                  float64\n",
      "o3                                   float64\n",
      "temperature                          float64\n",
      "humidity                               int64\n",
      "hospital_admissions                    int64\n",
      "population_density                    object\n",
      "hospital_capacity                      int64\n",
      "population_density_numeric           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print('Missing values in each column:')\n",
    "print(missing_values)\n",
    "\n",
    "# Handling missing values (basic strategy): drop rows with critical missing data\n",
    "df.dropna(subset=['date', 'aqi', 'pm2_5', 'hospital_admissions'], inplace=True)\n",
    "\n",
    "# Convert population_density to a numeric value if possible; if not possible, leave it as is\n",
    "try:\n",
    "    df['population_density_numeric'] = pd.to_numeric(df['population_density'], errors='coerce')\n",
    "    print('Converted population_density to numeric where possible.')\n",
    "except Exception as e:\n",
    "    print('Error converting population_density:', e)\n",
    "\n",
    "# For any remaining non-numeric entries in population_density_numeric, we can fill them with the median\n",
    "if 'population_density_numeric' in df.columns:\n",
    "    median_val = df['population_density_numeric'].median()\n",
    "    df['population_density_numeric'].fillna(median_val, inplace=True)\n",
    "\n",
    "# Final sanity check\n",
    "print('Data types after processing:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2885d2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Now we explore potential relationships in the data. In this section, we generate several plots:\n",
    "\n",
    "- Correlation heatmap for numeric features (only if four or more numeric columns exist).\n",
    "- Pair plot to assess distributions and relationships between key variables.\n",
    "- Histograms for distribution of individual numeric variables.\n",
    "- Count plot (pie chart style) for categorical features (e.g., city).\n",
    "\n",
    "Each plot is a step towards a more complete picture of the pollutant-health connection. Grab your binoculars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f79fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numeric columns for correlation analysis\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Generate a correlation heatmap if there are 4 or more numeric columns\n",
    "if numeric_df.shape[1] >= 4:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    corr = numeric_df.corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('D:/DSMLAI(insaid)/ML/practice/AIR-QUALITY/EDA-images/correlation_heatmap.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Not enough numeric columns for a correlation heatmap.')\n",
    "\n",
    "# Pair Plot of key variables\n",
    "sns.pairplot(df[['aqi', 'pm2_5', 'pm10', 'hospital_admissions']])\n",
    "plt.suptitle('Pair Plot of Selected Variables', y=1.02)\n",
    "plt.savefig('D:/DSMLAI(insaid)/ML/practice/AIR-QUALITY/EDA-images/pairplot.png')\n",
    "plt.show()\n",
    "\n",
    "# Histograms for numeric features\n",
    "numeric_cols = numeric_df.columns\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.savefig(f'D:/DSMLAI(insaid)/ML/practice/AIR-QUALITY/EDA-images/histogram_{col}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Count plot for the categorical 'city' feature\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='city', order=df['city'].value_counts().index)\n",
    "plt.title('Count Plot of Cities')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.savefig('D:/DSMLAI(insaid)/ML/practice/AIR-QUALITY/EDA-images/countplot_cities.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3de004",
   "metadata": {},
   "source": [
    "## Predictive Modeling\n",
    "\n",
    "Given that hospital admissions in the context of air quality metrics is a pressing health indicator, we develop a predictor to see if we can forecast hospital admissions using air quality data and related features. We select a subset of features that are both plausible and available in the dataset. In our case, the features include:\n",
    "\n",
    "- aqi\n",
    "- pm2_5\n",
    "- pm10\n",
    "- no2\n",
    "- o3\n",
    "- temperature\n",
    "- humidity\n",
    "- hospital_capacity\n",
    "\n",
    "We use a RandomForestRegressor as our predictive model. While simple linear models are elegant, we prefer the brute force of tree ensembles for capturing non-linearities. We then evaluate the model using R2 and Mean Squared Error on a hold-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf8d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 11.88\n",
      "R^2 Score: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Define the target and predictors\n",
    "target = 'hospital_admissions'\n",
    "features = ['aqi', 'pm2_5', 'pm10', 'no2', 'o3', 'temperature', 'humidity', 'hospital_capacity']\n",
    "\n",
    "# Drop any rows with missing values in the selected feature columns\n",
    "model_df = df.dropna(subset=features + [target]).copy()\n",
    "\n",
    "# Extract features X and target y\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2:.2f}')\n",
    "\n",
    "# Permutation importance to understand feature contributions\n",
    "perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "feature_importance = pd.Series(perm_importance.importances_mean, index=features)\n",
    "feature_importance = feature_importance.sort_values()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_importance.index, feature_importance.values, color='skyblue')\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174be4d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook takes us through loading, cleaning, and exploring air quality data in relation to public health outcomes. Our exploratory analysis highlights several key relationships, and the predictive modeling section demonstrates that a RandomForestRegressor can capture the complexity of these interactions to predict hospital admissions with a reasonable degree of accuracy. \n",
    "\n",
    "Merits of this approach include:\n",
    "\n",
    "- A comprehensive data cleaning methodology that handles date conversions and missing values robustly.\n",
    "- Multiple visualization methods that offer varied perspectives on the data.\n",
    "- A predictive model that uses permutation importance to highlight valuable features.\n",
    "\n",
    "Future analyses might incorporate time-series forecasting elements, integrate more granular geographical information, or experiment with other machine learning algorithms to further improve prediction accuracy.\n",
    "\n",
    "If you found this notebook useful, please consider upvoting it."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7610704,
     "sourceId": 12089877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
